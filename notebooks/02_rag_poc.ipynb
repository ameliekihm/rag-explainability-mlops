{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11803e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset (5% sample from squad_v2)\n",
    "dataset = load_dataset(\"squad_v2\", split=\"train\")\n",
    "sample_size = int(len(dataset) * 0.05)\n",
    "dataset_sample = dataset.shuffle(seed=42).select(range(sample_size))\n",
    "\n",
    "contexts = dataset_sample[\"context\"]\n",
    "questions = dataset_sample[\"question\"]\n",
    "answers = dataset_sample[\"answers\"]\n",
    "\n",
    "# Embedding model (e5-small)\n",
    "embedder = SentenceTransformer(\"intfloat/e5-small\")\n",
    "context_embeddings = embedder.encode(\n",
    "    contexts,\n",
    "    batch_size=16,\n",
    "    convert_to_numpy=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "dim = context_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(context_embeddings)\n",
    "\n",
    "# Generator model (flan-t5-small)\n",
    "generator = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\")\n",
    "\n",
    "def rag_answer(question, top_k=3):\n",
    "    q_emb = embedder.encode([question])\n",
    "    D, I = index.search(q_emb, top_k)\n",
    "    retrieved = [contexts[int(i)] for i in I[0]]\n",
    "    prompt = question + \" \\n\\n\" + \" \".join(retrieved)\n",
    "    answer = generator(prompt, max_length=128, num_return_sequences=1)[0]['generated_text']\n",
    "    return answer, retrieved\n",
    "\n",
    "# Example query\n",
    "q = \"Who wrote the Declaration of Independence?\"\n",
    "ans, ctxs = rag_answer(q)\n",
    "\n",
    "print(\"Q:\", q)\n",
    "print(\"Answer:\", ans)\n",
    "print(\"Retrieved Contexts:\", ctxs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d59457",
   "metadata": {},
   "source": [
    "### Initial PoC Results (5% Sample, e5-small + flan-t5-small)\n",
    "\n",
    "- **Query:** \"Who wrote the Declaration of Independence?\"  \n",
    "- **Answer:** *James Madison*  \n",
    "- **Retrieved Contexts:** The top-k results mostly contained passages about James Madison, not Thomas Jefferson.  \n",
    "\n",
    "**Interpretation**  \n",
    "- The pipeline works end-to-end: embedding ‚Üí vector search ‚Üí generation.  \n",
    "- However, the retrieved contexts did not include Jefferson, so the generator produced an incorrect answer (Madison).  \n",
    "- This shows a limitation in retrieval quality rather than in the generator itself.  \n",
    "\n",
    "**Implications**  \n",
    "- The initial RAG PoC is functional but highlights the need for accuracy improvements.  \n",
    "- Potential next steps include:  \n",
    "  - Tuning retrieval parameters (e.g., increasing *k*)  \n",
    "  - Trying different FAISS index types  \n",
    "  - Adding a reranker to improve context selection  \n",
    "  - Prompt engineering for better grounding in retrieved passages  \n",
    "\n",
    "üëâ This result should be recorded in `docs/initial_poc_results.md` as part of the **‚ÄúVector Search + Top-k Initial Report.‚Äù**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-explain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
