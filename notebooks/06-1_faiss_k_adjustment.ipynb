{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e91e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ 0. Install FAISS if not available\n",
    "!pip install faiss-cpu\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# ‚úÖ 1. Import modules\n",
    "import numpy as np\n",
    "import faiss\n",
    "import os\n",
    "\n",
    "# ‚úÖ 2. Load embeddings from Google Drive\n",
    "embedding_dir = \"/content/drive/My Drive/RAG Research/embeddings\"\n",
    "\n",
    "context_embeddings = np.load(os.path.join(embedding_dir, \"context_embeddings.npy\"))\n",
    "question_embeddings = np.load(os.path.join(embedding_dir, \"question_embeddings.npy\"))\n",
    "\n",
    "print(\"Context shape:\", context_embeddings.shape)\n",
    "print(\"Question shape:\", question_embeddings.shape)\n",
    "\n",
    "# ‚úÖ 3. Build FAISS Flat index\n",
    "embedding_dim = context_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "\n",
    "index.add(context_embeddings)\n",
    "print(f\" FAISS Index built with {index.ntotal} context vectors\")\n",
    "\n",
    "# ‚úÖ 4. Example Retrieval: Top-5 documents for first 3 queries\n",
    "k = 5\n",
    "D, I = index.search(question_embeddings[:3], k)\n",
    "\n",
    "for i, (distances, indices) in enumerate(zip(D, I)):\n",
    "    print(f\"\\nüîç Query {i+1}:\")\n",
    "    for rank, (idx, score) in enumerate(zip(indices, distances)):\n",
    "        print(f\"  Rank {rank+1}: Context ID {idx}, Distance {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea5a3e8",
   "metadata": {},
   "source": [
    "## Flat: Evaluating Performance (Recall@k, MRR) ‚Äî k set to 20 for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d05156",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load original SQuAD dataset (train split, same used for embeddings)\n",
    "dataset = load_dataset(\"squad_v2\", split=\"train\")\n",
    "\n",
    "# Ground truth: for each question i, the correct context is dataset[i][\"context\"]\n",
    "# Since embeddings were built in the same order, ground truth = i\n",
    "ground_truth = np.arange(len(dataset))\n",
    "\n",
    "# Search top-k for all questions\n",
    "k = 20\n",
    "D, I = index.search(question_embeddings, k)\n",
    "\n",
    "# Compute Recall@k\n",
    "recall_at_k = np.mean([\n",
    "    1 if ground_truth[i] in I[i] else 0\n",
    "    for i in range(len(question_embeddings))\n",
    "])\n",
    "\n",
    "# Compute MRR\n",
    "mrr = np.mean([\n",
    "    1 / (list(I[i]).index(ground_truth[i]) + 1)\n",
    "    if ground_truth[i] in I[i] else 0\n",
    "    for i in range(len(question_embeddings))\n",
    "])\n",
    "\n",
    "print(f\"Recall@{k}: {recall_at_k:.4f}\")\n",
    "print(f\"MRR: {mrr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d162ca08",
   "metadata": {},
   "source": [
    "## IVFFlat(Inverted File Flat Index): Evaluating Performance (Recall@k, MRR)‚Äî k set to 20 for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de547fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load embeddings\n",
    "embedding_dir = \"/content/drive/MyDrive/RAG Research/embeddings\"\n",
    "context_embeddings = np.load(f\"{embedding_dir}/context_embeddings.npy\")\n",
    "question_embeddings = np.load(f\"{embedding_dir}/question_embeddings.npy\")\n",
    "\n",
    "# IVFFlat index parameters\n",
    "d = context_embeddings.shape[1]\n",
    "nlist = 100   # number of clusters (tuneable)\n",
    "\n",
    "# Build IVFFlat\n",
    "quantizer = faiss.IndexFlatL2(d)\n",
    "index_ivf = faiss.IndexIVFFlat(quantizer, d, nlist, faiss.METRIC_L2)\n",
    "\n",
    "# Train and add\n",
    "index_ivf.train(context_embeddings)\n",
    "index_ivf.add(context_embeddings)\n",
    "\n",
    "print(\"‚úÖ IVFFlat index built and trained\")\n",
    "\n",
    "# Ground truth\n",
    "dataset = load_dataset(\"squad_v2\", split=\"train\")\n",
    "ground_truth = np.arange(len(dataset))\n",
    "\n",
    "# Search with full question set\n",
    "k = 20\n",
    "D, I = index_ivf.search(question_embeddings, k)\n",
    "\n",
    "# Recall@k\n",
    "recall_at_k = np.mean([\n",
    "    1 if ground_truth[i] in I[i] else 0\n",
    "    for i in range(len(question_embeddings))\n",
    "])\n",
    "\n",
    "# MRR\n",
    "mrr = np.mean([\n",
    "    1 / (list(I[i]).index(ground_truth[i]) + 1)\n",
    "    if ground_truth[i] in I[i] else 0\n",
    "    for i in range(len(question_embeddings))\n",
    "])\n",
    "\n",
    "print(f\"[IVFFlat] Recall@{k}: {recall_at_k:.4f}\")\n",
    "print(f\"[IVFFlat] MRR: {mrr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbd4f2f",
   "metadata": {},
   "source": [
    "## HNSW(Hierarchical Navigable Small World graph): Evaluating Performance (Recall@k, MRR) - k set to 20 for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44323b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "# Dimension of embeddings\n",
    "d = context_embeddings.shape[1]\n",
    "\n",
    "# Build HNSW index (Hierarchical Navigable Small World graph)\n",
    "hnsw_index = faiss.IndexHNSWFlat(d, 32)  # 32 = number of neighbors (M)\n",
    "hnsw_index.hnsw.efConstruction = 200     # construction parameter (higher = more accurate, slower build)\n",
    "\n",
    "# Add context embeddings\n",
    "hnsw_index.add(context_embeddings)\n",
    "print(f\"‚úÖ HNSW index built with {hnsw_index.ntotal} context vectors\")\n",
    "\n",
    "# Set search parameter (efSearch = trade-off between accuracy/speed)\n",
    "hnsw_index.hnsw.efSearch = 64\n",
    "\n",
    "# Search top-k for all questions\n",
    "k = 20\n",
    "D, I = hnsw_index.search(question_embeddings, k)\n",
    "\n",
    "# Compute Recall@k\n",
    "recall_at_k = np.mean([\n",
    "    1 if ground_truth[i] in I[i] else 0\n",
    "    for i in range(len(question_embeddings))\n",
    "])\n",
    "\n",
    "# Compute MRR\n",
    "mrr = np.mean([\n",
    "    1 / (list(I[i]).index(ground_truth[i]) + 1)\n",
    "    if ground_truth[i] in I[i] else 0\n",
    "    for i in range(len(question_embeddings))\n",
    "])\n",
    "\n",
    "print(f\"[HNSW] Recall@{k}: {recall_at_k:.4f}\")\n",
    "print(f\"[HNSW] MRR: {mrr:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
