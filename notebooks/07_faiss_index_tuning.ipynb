{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3900745e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 1. Setup\n",
    "!pip install -q faiss-cpu datasets\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "import time\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load precomputed embeddings (same as 06)\n",
    "context_embeddings = np.load(\"/content/drive/MyDrive/RAG Research/embeddings/context_embeddings.npy\")\n",
    "question_embeddings = np.load(\"/content/drive/MyDrive/RAG Research/embeddings/question_embeddings.npy\")\n",
    "\n",
    "\n",
    "d = context_embeddings.shape[1]\n",
    "print(f\"Embedding dim: {d}, Contexts: {len(context_embeddings)}, Questions: {len(question_embeddings)}\")\n",
    "\n",
    "# Ground truth\n",
    "dataset = load_dataset(\"squad_v2\", split=\"train\")\n",
    "ground_truth = np.arange(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494e9d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 2. Evaluation function (accuracy + latency)\n",
    "def evaluate_index(index, questions, ground_truth, k=10, n_trials=100):\n",
    "    start = time.time()\n",
    "    D, I = index.search(questions, k)\n",
    "    latency = (time.time() - start) / len(questions)  # avg per query\n",
    "\n",
    "    recall_at_k = np.mean([\n",
    "        1 if ground_truth[i] in I[i] else 0\n",
    "        for i in range(len(questions))\n",
    "    ])\n",
    "\n",
    "    mrr = np.mean([\n",
    "        1 / (list(I[i]).index(ground_truth[i]) + 1)\n",
    "        if ground_truth[i] in I[i] else 0\n",
    "        for i in range(len(questions))\n",
    "    ])\n",
    "\n",
    "    return recall_at_k, mrr, latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56344b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 3. Different k values (e.g., 5, 10, 20)\n",
    "k_values = [5, 10, 20]\n",
    "\n",
    "# Flat Index (baseline)\n",
    "index_flat = faiss.IndexFlatL2(d)\n",
    "index_flat.add(context_embeddings)\n",
    "\n",
    "for k in k_values:\n",
    "    recall, mrr, latency = evaluate_index(index_flat, question_embeddings, ground_truth, k=k)\n",
    "    print(f\"[Flat][k={k}] Recall@{k}: {recall:.4f}, MRR: {mrr:.4f}, Latency: {latency*1000:.2f} ms/query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77bb963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 4. IVFFlat (tuning nlist, nprobe)\n",
    "nlist = 100  # number of clusters\n",
    "quantizer = faiss.IndexFlatL2(d)\n",
    "index_ivf = faiss.IndexIVFFlat(quantizer, d, nlist)\n",
    "index_ivf.train(context_embeddings)\n",
    "index_ivf.add(context_embeddings)\n",
    "\n",
    "for nprobe in [1, 5, 10, 20]:\n",
    "    index_ivf.nprobe = nprobe\n",
    "    for k in k_values:\n",
    "        recall, mrr, latency = evaluate_index(index_ivf, question_embeddings, ground_truth, k=k)\n",
    "        print(f\"[IVFFlat][nprobe={nprobe}, k={k}] Recall@{k}: {recall:.4f}, MRR: {mrr:.4f}, Latency: {latency*1000:.2f} ms/query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf8abe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 5. HNSW (tuning efSearch)\n",
    "M = 32\n",
    "index_hnsw = faiss.IndexHNSWFlat(d, M)\n",
    "index_hnsw.hnsw.efConstruction = 200\n",
    "index_hnsw.add(context_embeddings)\n",
    "\n",
    "for efSearch in [16, 32, 64, 128]:\n",
    "    index_hnsw.hnsw.efSearch = efSearch\n",
    "    for k in k_values:\n",
    "        recall, mrr, latency = evaluate_index(index_hnsw, question_embeddings, ground_truth, k=k)\n",
    "        print(f\"[HNSW][efSearch={efSearch}, k={k}] Recall@{k}: {recall:.4f}, MRR: {mrr:.4f}, Latency: {latency*1000:.2f} ms/query\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
